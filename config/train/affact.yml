---
config:
  name: affact # name of the configuration file
basic:
  # The Cuda device ID, that is needed to enable GPU acceleration. Can also be several IDs seperated by Comma
  cuda_device_name: cuda:0
  # The name of the experiment
  experiment_name: AFFACT
  # The description and purpose of the experiment
  experiment_description: Train the AFFACT Network
  # The path to the result directory
  result_directory: "path/to/your/result_directory"
  # The name of the result folder
  result_directory_name: ''
  # if wandB should be enabled (0 = not enabled, 1 = enabled)
  enable_wand_reporting: 1
model:
  # The name of the model
  name: resnet_51
  # If pretrained weights should be used (0 = false, 1 = true)
  pretrained: 1
  # The rate of dropout (0.2-0.5 is recommended, only matters if chosen model has a dropout layer)
  dropout: 0
dataset:
  # Path to the partition file
  partition_filename: "path/to/your/partition_file"
  # Path to the labels' file
  dataset_labels_filename: "path/to/your/dataset_labels_file"
  # Path to the folder which contains the images
  dataset_image_folder: "path/to/your/dataset_image_folder"
  # bounding box mode (0 = align with landmarks, 1 = crop with the bounding box file, 2 = crop with a face detector)
  bounding_box_mode: 0
  # Scale the bounding box if bounding box mode 2 is selected
  bounding_box_scale: 2
  # Path to the file which contains the landmarks information
  landmarks_filename: "path/to/your/landmarks_file"
  # Path to the bounding box file
  bounding_boxes_filename: "path/to/your/bounding_boxes_file"
training:
  # How many epochs the model should be trained on
  epochs: 35
  # How often the to save the model's weight during training (e.g. 10 safes the model's weights every 10 epochs)
  save_frequency: 5
  optimizer:
    # Type of Optimizer (e.g. SGD for stochastic gradient descent)
    type: RMSprop
    # Learning rate (e.g. 0.001, 0.01, 0.1, 1)
    learning_rate: 0.0001
    # Momentum
    momentum: 0
  criterion:
    # Loss function that should be used (e.g. "BCEWithLogitsLoss")
    type: BCEWithLogitsLoss
  lr_scheduler:
    # Type of learning rate scheduler that adjusts the Learning rate dynamically during training (e.g. "ReduceLROnPlateau")
    type: ReduceLROnPlateau
    # LRscheduler: after how many epochs the learning rate is adjusted
    step_size: 7
    # multiplicator of learning rate. (e.g. new learning rate = old learning rate * gamma)
    gamma: 0.1
    # How many epochs to wait while the validation loss does not decrease before adjusting the learnig rate
    patience: 2
preprocessing:
  # Batch size of training and validation data (training data is split in equal sets of size batch size)
  dataloader:
    # If the data is shuffled before it is split in batches (True for shuffling and False for not shuffling)
    batch_size: 64
    # If the data is shuffled before it is split in batches (True for shuffling and False for not shuffling)
    shuffle: 'True'
    # how many images to preprocess at the same time (>1 uses multiprocessing, suggested around 8 if training on 1 gpu)
    num_workers: 8
    # How many batches are preprocessed on each worker
    prefetch_factor: 10
  save_preprocessed_image:
    # If enabled, saves images in defined frequency
    enabled: 0
    frequency: 1000
  transformation:
    crop_size:
      # image gets aligned/cropped and then resized before training
      x: 224
      y: 224
    scale_jitter:
      # Enable scale jitter (0 = disabled, 1 = enabled)
      enabled: 1
      normal_distribution:
        mean: 0
        std: 0.1
    angle_jitter:
      # Enable angle jitter (0 = disabled, 1 = enabled)
      enabled: 1
      normal_distribution:
        mean: 0
        std: 20
    shift_jitter:
      # Enable shift jitter (0 = disabled, 1 = enabled)
      enabled: 1
      normal_distribution:
        mean: 0
        std: 0.05
    mirror:
      # Enable mirroring (0 = disabled, 1 = enabled)
      enabled: 1
      probability: 0.5
    gaussian_blur:
      # Enable gaussian blur (0 = disabled, 1 = enabled)
      enabled: 1
      normal_distribution:
        mean: 0
        std: 3
    gamma:
      # Enable gamma (0 = disabled, 1 = enabled)
      enabled: 1
      normal_distribution:
        mean: 0
        std: 1
    temperature:
      # Enable temperature (0 = disabled, 1 = enabled)
      enabled: 0
